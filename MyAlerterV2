import engine.AITask
import java.time.LocalDateTime
import java.time.format.DateTimeFormatter
import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.mllib.linalg.{Vectors, Vector, SparseVector}
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.util.MLUtils
import org.apache.spark.sql.{SaveMode, SparkSession}
	  
new AITask {
  override def run(payload: String): Unit = {
	try {
	  val spark = SparkSession.builder.master(param("master")).appName(node).getOrCreate()
	  import spark.implicits._
	  MLUtils.convertVectorColumnsToML(Seq(LabeledPoint(LocalDateTime.now.format(DateTimeFormatter.ofPattern("YYYYMMddHHmmss")).toDouble, Vectors.sparse(1,Array(0),Array(payload.toDouble)))).toDF()).write.format("libsvm").mode(SaveMode.Append).save(param("path"))	  
      val dataset = MLUtils.convertVectorColumnsToML(spark.createDataset(MLUtils.loadLibSVMFile(spark.sparkContext,param("path"))))
	  val kmeans = new KMeans().setK(3).setSeed(1L)
      val model = kmeans.fit(dataset)
      val predictions = model.transform(dataset)
	  val c = model.clusterCenters.map(v => v.apply(0))
      val sc = c.sorted
      val color = predictions.collect().filter(r => r.getAs[org.apache.spark.ml.linalg.SparseVector](1).apply(0) == payload.toDouble).map(r => sc.indexOf(c.apply(r.getInt(2))) match {
        case 0 => "green"
        case 1 => "yellow"
        case 2 => "red"
      }).apply(0)
	  if(color == "red") postOutput(payload)
	  postStatus(s""" { "shape": "dot", "fill": "$color", "text": "$payload"}""")
    }
    catch {
      case e:Exception => println(s"Exception: ${e.getMessage}")
    }
  }
}